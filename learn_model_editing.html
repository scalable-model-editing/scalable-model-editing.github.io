<!DOCTYPE html>
<html lang="en">
<head>
    <link rel="stylesheet" href="style.css">
    <title>Learning Model Editing - Research Projects</title>
</head>
<body>
    <nav>
        <ul>
            <div class="nav-container">
                <li class="nav-logo1"><img src="UC Berkeley.png" alt="Logo 2"></li>
                <li class="nav-logo"><img src="BAIR.png" alt="Logo 1"></li>
            </div>
            <div class="nav-links">
                <li><a href="index.html">Home</a></li>
                <li><a href="papers.html">List of Papers</a></li>
                <li><a href="team.html">Team</a></li>
                <li><a href="learn_model_editing.html">Model Editing Resources</a></li>
            </div>
        </ul>
        <div class="title-separator"></div>
    </nav>
    <div class="container">

        <section>
            <h2>Resources for Learning Model Editing</h2>
            In this page, we provide a list of learning resources to get started with model editing. We also provide video explanations of different papers where available. We are actively working on increasing our collection of video explanation of papers.

            <div>
                <h3>FUNDAMENTAL METHODS FOR MODEL EDITING</h3>
                <ul>
                    <li>Transformer Feed-Forward Layers Are Key-Value Memories - <a href="https://arxiv.org/pdf/2012.14913.pdf"> Paper Link</a>, <a href="https://youtu.be/Y6vawvUgrKg">Video Explanation</a> </li>
                    <li>Editing Factual Knowledge in Language Models - <a href="https://arxiv.org/pdf/2104.08164.pdf">Paper Link</a></li>
                    <li>Knowledge Neurons in Pretrained Transformers - <a href="https://arxiv.org/pdf/2104.08696.pdf">Paper Link</a></li>
                    <li>MEND - Fast Model Editing at Scale - <a href="https://arxiv.org/pdf/2110.11309.pdf">Paper Link</a>, <a href="https://youtu.be/HPms9f5QcnU">Video Explanation</a></li>
                    <li>ROME - Locating and Editing Factual Associations in GPT - <a href="https://arxiv.org/pdf/2202.05262.pdf">Paper Link</a>, <a href="https://www.youtube.com/watch?v=_NMQyOu2HTo">Video by original authors</a></li>
                    <li>SERAC - Memory-Based Model Editing at Scale - <a href="https://arxiv.org/pdf/2206.06520.pdf">Paper Link</a>, <a href="https://youtu.be/IwfBR1CwG_k">Video Explanation</a></li>
                    <li>MEMIT - Mass-Editing Memory in a Transformer - <a href="https://arxiv.org/pdf/2210.07229.pdf">Paper Link</a></li>
                    <li>A Unified Framework for Model Editing - <a href="https://arxiv.org/pdf/2403.14236">Paper Link</a></li>
                    <li>MALMEN - Massive Editing for Large Language Model via Meta Learning - <a href="https://arxiv.org/pdf/2311.04661">Paper Link</a></li>
                </ul>
                <h3>SELECTED ANALYSIS PAPERS FOR MODEL EDITING</h3>
                <ul>
                    <li>Does Localization Inform Editing? - <a href="https://arxiv.org/pdf/2301.0421.pdf">Paper Link</a></li>
                    <li>Evaluating the Ripple Effects of Knowledge Editing in Language Models - <a href="https://arxiv.org/pdf/2307.12976.pdf">Paper Link</a></li>
                    <li>Unveiling the Pitfalls of Knowledge Editing for Large Language Models - <a href="https://arxiv.org/pdf/2310.02129.pdf">Paper Link</a></li>
                    <li>Model Editing at Scale leads to Gradual and Catastrophic Forgetting - <a href="https://arxiv.org/pdf/2401.07453.pdf">Paper link</a></li>
                    <li>Editing Large Language Models: Problems, Methods, and Opportunities - <a href="https://arxiv.org/pdf/2305.13172.pdf">Paper Link</a></li>
                    <li>Is Bigger Edit Batch Size Always Better? - An Empirical Study on Model Editing with Llama-3 - <a href="paper4/index.html">Paper Link</a></li>
                    
                </ul>
            </div>
            
        </section>
    </div>
    <footer>
        <p>&copy; 2024 UC Berkeley. All rights reserved.</p>
    </footer>
</body>
</html>
